{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flair Tutorial 9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEAHUiNyeex6",
        "colab_type": "text"
      },
      "source": [
        "# Tutorial 9: Training your own Flair Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfkLQWQyek3S",
        "colab_type": "text"
      },
      "source": [
        "## A. Preparing a Text Corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3cVnPjeePUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# corpus/\n",
        "# corpus/train/\n",
        "# corpus/train/train_split_1\n",
        "# corpus/train/train_split_2\n",
        "# corpus/train/...\n",
        "# corpus/train/train_split_X\n",
        "# corpus/test.txt\n",
        "# corpus/valid.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qclI9jQ-exrH",
        "colab_type": "text"
      },
      "source": [
        "## B. Training the Language Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUKMX3NOfLr5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e00b002e-52ca-4a3e-ea1e-9edf5dcd1ec6"
      },
      "source": [
        "!pip install flair"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flair in /usr/local/lib/python3.6/dist-packages (0.4.4)\n",
            "Requirement already satisfied: transformers>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from flair) (2.2.2)\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.6/dist-packages (from flair) (3.1.2)\n",
            "Requirement already satisfied: deprecated>=1.2.4 in /usr/local/lib/python3.6/dist-packages (from flair) (1.2.7)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from flair) (0.1.2)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.6/dist-packages (from flair) (3.10.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from flair) (0.8.6)\n",
            "Requirement already satisfied: sqlitedict>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.6.0)\n",
            "Requirement already satisfied: mpld3==0.3 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.20 in /usr/local/lib/python3.6/dist-packages (from flair) (1.24.3)\n",
            "Requirement already satisfied: ipython==7.6.1 in /usr/local/lib/python3.6/dist-packages (from flair) (7.6.1)\n",
            "Requirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.6/dist-packages (from flair) (4.28.1)\n",
            "Requirement already satisfied: torch>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from flair) (1.3.1)\n",
            "Requirement already satisfied: bpemb>=0.2.9 in /usr/local/lib/python3.6/dist-packages (from flair) (0.3.0)\n",
            "Requirement already satisfied: gensim>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.0)\n",
            "Requirement already satisfied: tiny-tokenizer[all] in /usr/local/lib/python3.6/dist-packages (from flair) (3.0.1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (from flair) (0.0)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.6/dist-packages (from flair) (1.0.7)\n",
            "Requirement already satisfied: ipython-genutils==0.2.0 in /usr/local/lib/python3.6/dist-packages (from flair) (0.2.0)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from flair) (0.4.2)\n",
            "Requirement already satisfied: pytest>=3.6.4 in /usr/local/lib/python3.6/dist-packages (from flair) (3.6.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from flair) (2019.12.9)\n",
            "Requirement already satisfied: segtok>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from flair) (1.5.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers>=2.0.0->flair) (0.1.85)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers>=2.0.0->flair) (1.10.40)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers>=2.0.0->flair) (1.17.4)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=2.0.0->flair) (0.0.35)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers>=2.0.0->flair) (2.21.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.4.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (2.6.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.6/dist-packages (from deprecated>=1.2.4->flair) (1.11.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.3.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (2.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from hyperopt>=0.1.1->flair) (1.12.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.15.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.3.3)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (2.0.10)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.7.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (4.4.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (0.1.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (42.0.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython==7.6.1->flair) (2.1.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.4.0->flair) (1.9.0)\n",
            "Requirement already satisfied: SudachiPy; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from tiny-tokenizer[all]->flair) (0.4.2)\n",
            "Requirement already satisfied: natto-py; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from tiny-tokenizer[all]->flair) (0.9.0)\n",
            "Requirement already satisfied: kytea; extra == \"all\" in /usr/local/lib/python3.6/dist-packages (from tiny-tokenizer[all]->flair) (0.1.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn->flair) (0.21.3)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->flair) (4.3.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (19.3.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (8.0.2)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.3.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest>=3.6.4->flair) (1.8.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers>=2.0.0->flair) (1.13.40)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.0.0->flair) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers>=2.0.0->flair) (0.14.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.0.0->flair) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.0.0->flair) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers>=2.0.0->flair) (3.0.4)\n",
            "Requirement already satisfied: parso>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from jedi>=0.10->ipython==7.6.1->flair) (0.5.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.6.1->flair) (0.1.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython==7.6.1->flair) (0.6.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (2.49.0)\n",
            "Requirement already satisfied: sortedcontainers~=2.1.0 in /usr/local/lib/python3.6/dist-packages (from SudachiPy; extra == \"all\"->tiny-tokenizer[all]->flair) (2.1.0)\n",
            "Requirement already satisfied: dartsclone~=0.6.0 in /usr/local/lib/python3.6/dist-packages (from SudachiPy; extra == \"all\"->tiny-tokenizer[all]->flair) (0.6)\n",
            "Requirement already satisfied: cffi in /usr/local/lib/python3.6/dist-packages (from natto-py; extra == \"all\"->tiny-tokenizer[all]->flair) (1.13.2)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from pillow>=4.1.1->torchvision->flair) (0.46)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.40->boto3->transformers>=2.0.0->flair) (0.15.2)\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from dartsclone~=0.6.0->SudachiPy; extra == \"all\"->tiny-tokenizer[all]->flair) (0.29.14)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi->natto-py; extra == \"all\"->tiny-tokenizer[all]->flair) (2.19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsNqOIE1e0NB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "64821e36-238e-4085-b86e-b6f689752f1c"
      },
      "source": [
        "from flair.data import Dictionary\n",
        "from flair.models import LanguageModel\n",
        "from flair.trainers.language_model_trainer import LanguageModelTrainer\n",
        "from flair.trainers.language_model_trainer import TextCorpus"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sUcyV-kfFzS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "52dea77b-d3d1-4ba7-94ee-a5f6e260a017"
      },
      "source": [
        "# are you training a forward or backward LM?\n",
        "is_forward_lm = True\n",
        "\n",
        "# load the default character dictionary\n",
        "dictionary: Dictionary = Dictionary.load('chars')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-20 18:07:52,687 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/models/common_characters not found in cache, downloading to /tmp/tmp57zc9qk0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2887/2887 [00:00<00:00, 1369326.66B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-20 18:07:53,347 copying /tmp/tmp57zc9qk0 to cache at /root/.flair/datasets/common_characters\n",
            "2019-12-20 18:07:53,347 removing temp file /tmp/tmp57zc9qk0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0h3xJWM4fmXs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get your corpus, process forward and at the character level\n",
        "# corpus = TextCorpus('/path/to/your/corpus',\n",
        "#                     dictionary,\n",
        "#                     is_forward_lm,\n",
        "#                     character_level = True)\n",
        "\n",
        "# instantiate your language model, set hidden size and \n",
        "# number of layers\n",
        "# language_model = LanguageModel(dictionary,\n",
        "#                                is_forward_lm,\n",
        "#                                hidden_size = 128,\n",
        "#                                nlayers = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF_Fju1qf7Eu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train your language model\n",
        "# trainer = LanguageModelTrainer(language_model, corpus)\n",
        "\n",
        "# trainer.train('resources/taggers/language_model',\n",
        "#               sequence_length = 10,\n",
        "#               mini_batch_size = 10,\n",
        "#               max_epochs = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS-EF5GLgX1v",
        "colab_type": "text"
      },
      "source": [
        "## C. Using the LM as Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zl3AmJHSgO-2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data import Sentence\n",
        "from flair.embeddings import FlairEmbeddings\n",
        "\n",
        "sentence = Sentence('I love Berlin')\n",
        "\n",
        "# init embeddings from your trained LM\n",
        "# char_lm_embeddings = FlairEmbeddings('resources/taggers/language-model/best-lm.pt')\n",
        "\n",
        "# embed sentence\n",
        "# char_lm_embeddings.embed(sentence)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ns981OEWg9IU",
        "colab_type": "text"
      },
      "source": [
        "## D. Non-Latin Alphabets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZECTlV1qg48k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make an empty character dictionary\n",
        "from flair.data import Dictionary\n",
        "char_dictionary: Dictionary = Dictionary()\n",
        "\n",
        "# counter object\n",
        "import collections\n",
        "counter = collections.Counter()\n",
        "\n",
        "processed = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "skrzD0KRhevj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "files = glob.glob('/path/to/your/corpus/files/*.*')\n",
        "\n",
        "print(files)\n",
        "for file in files:\n",
        "  print(file)\n",
        "\n",
        "  with open(file, 'r', encoding = 'utf-8') as f:\n",
        "    tokens = 0\n",
        "    for line in f:\n",
        "\n",
        "      processed += 1\n",
        "      chars = list(line)\n",
        "      tokens += len(chars)\n",
        "\n",
        "      # Add chars to the dictionary\n",
        "      counter.update(chars)\n",
        "\n",
        "      # comment this line in to speed things up (if corpus is too large)\n",
        "      # if tokens > 50000000: break\n",
        "\n",
        "  # break\n",
        "\n",
        "total_count = 0\n",
        "for letter, count in counter.most_common():\n",
        "  total_count += count\n",
        "\n",
        "print(total_count)\n",
        "print(processed)\n",
        "\n",
        "sum = 0\n",
        "idx = 0\n",
        "for letter, count in counter.most_common():\n",
        "  sum += count\n",
        "  percentile = (sum / total_count)\n",
        "\n",
        "  # comment this line in to use only top X percentile of chars\n",
        "  # otherwise filter later\n",
        "  # if percentile < 0.00001: break\n",
        "\n",
        "  char_dictionary.add_item(letter)\n",
        "  idx += 1\n",
        "  print('%d\\t%s\\t%7d\\t%7d\\t%f' % (idx, letter, count, sum, percentile))\n",
        "\n",
        "print(char_dictionary.item2idx)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oLRXeQgiiFD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "with open('/path/to/your_char_mappings', 'wb') as f:\n",
        "  mappings = {\n",
        "      'idx2item': char_dictionary.idx2item,\n",
        "      'item2idx': char_dictionary.item2idx\n",
        "  }\n",
        "  pickle.dump(mappings, f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKsm1Z59i7x1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "dictionary = Dictionary.load_from_file('/path/to/your_char_mappings')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdQdA3T6jH2G",
        "colab_type": "text"
      },
      "source": [
        "## E. Fine-Tuning an Existing LM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Er25hggjKig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from flair.data import Dictionary\n",
        "from flair.embeddings import FlairEmbeddings\n",
        "from flair.trainers.language_model_trainer import LanguageModelTrainer\n",
        "from flair.trainers.language_model_trainer import TextCorpus"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ae_vfDrj4v0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "8a5409e3-1369-447c-8166-2bc7479da82c"
      },
      "source": [
        "# instantiate an existing LM, such as one from the FlairEmbeddings\n",
        "language_model = FlairEmbeddings('news-forward').lm\n",
        "\n",
        "# are you fine-tuning a forward or backward LM?\n",
        "is_forward_lm = language_model.is_forward_lm\n",
        "\n",
        "# get the dictionary from the existing language model\n",
        "dictionary: Dictionary = language_model.dictionary"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2019-12-20 18:27:52,114 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/big-news-forward--h2048-l1-d0.05-lr30-0.25-20/news-forward-0.4.1.pt not found in cache, downloading to /tmp/tmpxi1j9hxu\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 73034624/73034624 [00:05<00:00, 13068216.18B/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-20 18:27:58,365 copying /tmp/tmpxi1j9hxu to cache at /root/.flair/embeddings/news-forward-0.4.1.pt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2019-12-20 18:27:58,436 removing temp file /tmp/tmpxi1j9hxu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbvEYf3VkLVT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get your corpus, process forward and at the character level\n",
        "corpus = TextCorpus('path/to/your/corpus',\n",
        "                    dictionary,\n",
        "                    is_forward_lm,\n",
        "                    character_level = True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUlbaFLjkb22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# use the model trainer to fine-tune this model on your corpus\n",
        "trainer = LanguageModelTrainer(language_model, corpus)\n",
        "\n",
        "trainer.train('resources/taggers/language_model',\n",
        "              sequence_length= 100,\n",
        "              mini_batch_size = 100,\n",
        "              learning_rate = 20,\n",
        "              patience = 10,\n",
        "              checkpoint = True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}